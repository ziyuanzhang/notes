# AI-2-开发认知

- AI 开发分层体系

  ![AI开发分层体系](./img/AI体系/AI开发分层体系-千问.png)

  ![AI开发分层体系](./img/AI体系/AI开发分层体系-GPT.png)

- AI 职位分类 及 需要掌握的知识

  1. 大模型应用工程师(agent 工程师)：不做优化，直接用
  2. 大模型研发（开发）工程师：推理优化、模型微调
  3. 大模型算法工程师：大模型预训练、算法优化---》研究算法（研究开发下一代大模型的）

  ![大模型应用工程师与开发工程师](./img/AI体系/大模型应用工程师与开发工程师.png)

- 大模型的分类

  ![大模型的种类](./img/AI体系/大模型的种类.png)

- 大模型推理框架（能运行大模型的工具 == 把模型跑起来的工具或技术）

  ollama: 个人级别的；下面是企业级：

  ![大模型推理框架(把模型跑起来的工具或技术)](<./img/AI体系/大模型推理框架(把模型跑起来的工具或技术).png>)

## Prompt--》Agent--》Function Call--》RAG--》Fine tune--》垂直行业 LLM

- Agent 运行流程

  ![agent-1-推理](./img/agent/agent-1-推理.png)

  ![agent-2-行动](./img/agent/agent-2-行动.png)

  ![agent-3-观察](./img/agent/agent-3-观察.png)

  ![agent-4-循环](./img/agent/agent-4-循环.png)

  ![agent流程图](./img/operating_process/agent流程图.png)

- 需要掌握的技术

  1. Agent: LangGraph，多智能体架构，MCP，Tool，上下文工程
  2. RAG: Milvus、FAISS 等向量数据库，嵌入模型，多模态解析模型，GraphRAG(图数据库)，多模态 RAG，RAGAS（快速评估 RAG 系统的性能） 等

- 三个技术层面（从易到难）：

  1. 应用层技术：Prompt、Agent、Function Calling、RAG
  2. 优化层技术：Fine-tuning、模型蒸馏
  3. 底层技术：垂直行业 LLM 开发、预训练

- 实际工作中的技术栈组合：

  1. 新手/应用工程师：精通 Prompt + RAG + Agent 框架
  2. 进阶/研发工程师：掌握 Fine-tuning + 模型优化 + 部署
  3. 专家/算法工程师：深入预训练 + 模型架构 + 算法创新

## 预训练模型、微调、推理

1. 预训练模型：刚毕业的医学生
2. 微调：实习期，专攻一个方向
3. 推理：坐诊，看病

- 微调（Fine-tuning）和推理（Inference）

  1. 先微调 → 后推理。
  2. vllm: 只做推理，不能做微调
  3. vLLM 的 社区 MPS(Metal Performance Shaders)✅ 与 llama.cpp + GGUF ❎【学不到 vLLM 的部署技能】

- 微调：

  1. 全参数微调（Full Fine-tuning），【全参数微调（Full Fine-tuning）】，精度最高，但显存/算力要求高（需多卡 A100/H100）
  2. 高效微调（Parameter-Efficient FT），【PEFT（LoRA, QLoRA, IA³） + Transformers】，只训练少量参数，节省 70%+ 显存，适合 7B–70B 模型
  3. QLoRA 微调（4-bit 量化 + LoRA），【BitsAndBytes + PEFT + Transformers】，在单张 24G GPU（如 RTX 4090）上微调 65B 模型
  4. 大模型分布式训练，【DeepSpeed（ZeRO-3）、Megatron-LM、FSDP（PyTorch）】，百亿/千亿模型，千卡集群
  5. 云平台托管微调，【AWS SageMaker、Azure ML、Google Vertex AI、Databricks】，无需管理基础设施，按需付费
     **当前企业主流选择**：QLoRA + PEFT + Transformers —— 性价比高、社区支持好、可复现性强。

## AI 原生应用架构的关键点补充

- 企业实践建议：

  1. 通用任务 → 使用 API（GPT/Claude/DeepSeek）
  2. 专业领域 → RAG + 通用模型（解决 90%问题）
  3. 高频固定任务 → Fine-tuning 专用小模型
  4. 核心业务 → 自研垂直模型（护城河）

- RAG 系统的优化路径

  1. 基础 RAG:简单检索 --> 向量搜索
  2. 进阶 RAG: 混合检索 --> Query 改写 --> 重排序 --> 图增强
  3. 生产级 RAG:智能路由 --> 缓存策略 --> 多模态 RAG --> 评估体系

- Agent 设计的演进

  1. 单 Agent: 工具调用 --> 记忆机制 --> 推理能力
  2. 多 Agent 协作:角色分工 --> 通信协议 --> 竞争协作
  3. 企业级 Agent 系统:工作流编排 --> 监控管理 --> 安全控制

## 工具栈推荐

- 向量数据库选择

  1. 入门/原型: Chroma, FAISS
  2. 中小项目: Pinecone, Weaviate
  3. 大型生产: Milvus, Qdrant, Elasticsearch

- 开发环境 -- 企业生产:
  1. vLLM/TGI (推理优化)
  2. FastAPI (服务封装)
  3. Docker/K8s (部署运维)
  4. Prometheus/Grafana (监控)

## 常见误区提醒

1. 不要过度追求大模型：7B-13B 模型配合 RAG，能解决 80%的企业需求
2. RAG 不是万能的：对于逻辑复杂、需要深度推理的任务，可能需要微调
3. Agent 不是必须的：简单任务直接用链式调用，复杂任务再上 Agent
4. 评估要前置：在开发初期就要建立评估体系，而不是最后补

## 技术栈全景图

### 分层架构

```bash
┌──────────────────────────────────────────────────┐
│                应用层：AI原生应用                   │
├──────────────────────────────────────────────────┤
│          框架层：LangChain、LlamaIndex、AutoGen    │
├──────────────────────────────────────────────────┤
│        模型层：GPT、Claude、Qwen、DeepSeek          │
├──────────────────────────────────────────────────┤
│       基础设施：PyTorch、SiliconFlow、vLLM          │
└──────────────────────────────────────────────────┘
```

### 工具选型矩阵

| 需求场景      | 推荐工具栈                     | 特点             |
| ------------- | ------------------------------ | ---------------- |
| 个人学习/原型 | Ollama + LangChain + Streamlit | 简单快速、低门槛 |
| 中小企业      | vLLM + FastAPI + Docker        | 生产就绪、易部署 |
| 大型企业      | K8s + 多模型网关 + 监控体系    | 高可用、可扩展   |
| 特定领域      | 垂直模型 + RAG + Fine-tuning   | 专业深度、高精度 |

- 企业私有化 = 推理引擎 + 运维体系 + 安全合规

  1. 大型企业/高并发： vLLM on K8s + NVIDIA GPU + API 网关 + 监控
  2. 中型企业/稳定优先： TGI（Hugging Face） + K8s
  3. 小团队/MVP 验证： TGI 单机 Docker（比 Ollama 更生产就绪）
  4. 开发者本地/学习： Ollama 或 vLLM-MPS（Mac）

## 项目架构示例

### 企业知识库系统架构

```bash
┌──────────────────────────────────────────────────────────────┐
│                        用户界面层                              │
├──────────────────────────────────────────────────────────────┤
│                       API 网关与路由                           │
├──────────────────────────────────────────────────────────────┤
│  查询理解      │  检索增强       │  生成优化      │  评估反馈      │
├───────────────┬───────────────┬───────────────┬──────────────┤
│  • Query 改写  │  • 混合检索    │  • 提示工程     │  • RAGAS    │
│  • 意图识别    │  • 向量搜索     │  • 思维链      │  • 人工审核   │
│  • 多轮对话    │  • 全文检索     │  • 多模型融合   │  • A/B测试   │
├───────────────┴───────────────┴───────────────┴──────────────┤
│                     数据与基础设施层                            │
│                向量DB   文档解析   模型服务                     │
└──────────────────────────────────────────────────────────────┘
```

### 多 Agent 协作系统

```bash
┌─────────────────────────────────────────────────────────────────┐
│                         协调 Agent（Orchestrator）               │
├───────────────┬───────────────┬───────────────┬─────────────────┤
│   规划 Agent   │   执行 Agent   │   验证 Agent  │     学习 Agent   │
├───────────────┼───────────────┼─────────────-─┼─────────────────┤
│  • 任务分解     │  • 工具调用    │  • 结果验证    │  • 经验积累       │
│  • 优先级排序   │  • 状态管理    │  • 质量评估    │  • 策略优化       │
│  • 资源分配     │  • 错误处理    │  • 安全审查    │  • 性能调优       │
└───────────────┴───────────────┴───────────────┴──────────────────┘
```

## 实战学习路径

- 阶段一：基础掌握（1-2 个月）

  1. 第一周：大模型原理与 Prompt 工程
  2. 第二周：RAG 基础与向量数据库
  3. 第三周：Function Calling 与工具集成
  4. 第四周：单 Agent 开发实战

- 阶段二：进阶实践（2-3 个月）

  1. 第五周：高级 RAG 技术优化
  2. 第六周：多 Agent 协作系统
  3. 第七周：模型微调实战（LoRA）
  4. 第八周：评估体系与监控

- 阶段三：项目实战（2-3 个月）
  1. 项目 1：企业知识库系统（RAG 冠军方案）
  2. 项目 2：智能客服助手（多 Agent）
  3. 项目 3：数据分析平台（Text-to-SQL）
  4. 项目 4：工作流自动化（企业集成）

## 不管是个人电脑还是云平台，搭建聊天机器人的步骤为

1. 后端和模型部署

   - 个人电脑，后端使用 Ollama 框架搭配 deepseek-r1、qwen 模型
   - 云平台，后端使用 LangChain 框架搭配阿里云百炼平台、通义千问
   - Ollama 只有“模型”，入门级；比 Langchain 框架简单很多；

2. 前端部署，个人电脑或云平台均可使用 Streamlit
   - 个人电脑：chatbox/Cherry-Studio；公司网页：Open-WebUI

- ollama 介绍

  1. ollama: 是一款旨在简化大型语言模型本地部署和运行过程的开源软件，
  2. ollama: 提供了一个轻量级、易于扩展的框架，让开发者能够在本地机器上轻松构建和管理 LLMS(大型语言模型)
  3. 通过 ollama，开发者可以导入和定制自己的模型，无需关注复杂的底层实现细节。
  4. 网址: https://ollama.com

  - 常用操作：
    - ollama list 【查看已安装的模型】
    - ollama pull llama2:13b 【拉取模型但不运行】
    - ollama rm llama2 【删除模型】
    - ollama run qwen:7b 【启动模型并运行】
    - ollama ps 【查看正在运行的模型】
    - ollama stop <模型名> 【停止当前运行的模型】
    - 运行 Qwen3--》退出后（Ctrl+D），再运行 DeepSeek

## 模型广场

1. 硅基流动：【企业、开发者】 面向开发者和企业的高性能大模型推理与部署平台。

2. 小爱 ai：【个人开发者、小团队】 基于 OneAPI 的聚合型 AI 服务平台（由 Calcium-Ion 开发）。

   - 网址：https://xiaoai.plus/

3. 阿里百炼：【企业、AI 工程师】一站式大模型开发及应用构建平台。

4. ModelScope(魔搭)：【研究者、学生、开发者】模型开放平台

##

Valkey(Redis 的开源版)，RAGFlow,

1. langchain:深度定制的王者；给算法和后端工程师用的，

2. Coze: 零代码 AI 智能体（Agent）开发平台

   - 极低 (零代码)；
   - 闭源；仅限云服务；
   - 无需任何编程，通过聊天和拖拽，最快速度创建并发布功能丰富的 AI 聊天机器人到各平台

3. Dify: 低代码/可视化 AI 应用开发平台

   - 低 (低代码/可视化)
   - 开源；支持云服务和私有化部署
   - 通过可视化工作流编排，一站式快速构建和运维多种 AI 应用（如聊天机器人、知识库、Agent）

4. n8n: 通用型工作流自动化平台

   - 中 (可视化但逻辑复杂)
   - 开源（公平代码）；极易自托管，资源消耗低
   - 通用型工作流自动化平台 连接数百个应用与 API，实现跨系统的业务流程自动化，并可集成 AI 模型节点来增强流程智能

5. FastGPT: RAGFlow 的竞争对手；

   - 服务器配置低
   - 开源；支持私有化部署
   - 没有 RAGFlow 功能强

6. RAGFlow: 是一个开源、本地化部署的检索增强生成（RAG）系统

   - 中高 (需一定技术背景)
   - 开源；支持私有化部署
   - 对复杂格式文档（如 PDF、表格、扫描件）进行深度解析，实现高精度、可溯源的文档问答

- 用 RAGFlow 处理文档解析，用 Dify 编排业务流程，用 n8n 连接外部系统

- Claude: 是 Anthropic 公司对标老雇主 OpenAI 的拳头产品；
- Cursor: 内置 AI 的编辑器；
- Manus: 通用 AI 智能体 (AI Agent)

##

- Mac mini（M2 + 24GB 内存） + macOS Sequoia 15.5 + Xcode 16.4 学习 AI 开发(部署大模型)， 不影响办公（例：vscode PyCharm）；
- PyCharm python（3.11+）,用 uv 怎么安装 vllm（已经 0.12.0 了），PyTorch（已经 2.9 了），下载 4B 量化大模型，并运行；
- 未来会在 linux 上部署；用 langchain1.x；
