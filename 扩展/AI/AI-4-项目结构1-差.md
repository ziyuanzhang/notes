# AI-4-é¡¹ç›®ç»“æ„.md

## ä¸€ã€Repo æ€»ä½“ç»“æ„ï¼ˆæ¨èï¼‰

```text
rag-agent-system/
â”œâ”€â”€ README.md
â”œâ”€â”€ docker-compose.yml            # å¯é€‰ï¼šç»Ÿä¸€æ‹‰èµ·æœåŠ¡
â”œâ”€â”€ .env                          # ç¯å¢ƒå˜é‡ï¼ˆæ¨¡å‹ / API / åœ°å€ï¼‰
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ agent-gateway/            # â­ æ ¸å¿ƒï¼šAgent + Tool è°ƒåº¦
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI å…¥å£
â”‚   â”‚   â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ runner.py      # Agent Loopï¼ˆæ ¸å¿ƒé€»è¾‘ï¼‰
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py     # System / Tool Prompt
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tools.py       # Tool Schema å®šä¹‰
â”‚   â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ vllm_client.py # vLLM OpenAI å®¢æˆ·ç«¯
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ client.py      # fastMCP Client å°è£…
â”‚   â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ragflow.py     # RAGFlow API è°ƒç”¨
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ chat.py        # Pydantic è¯·æ±‚/å“åº”æ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ config.py          # é…ç½®åŠ è½½
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â”œâ”€â”€ mcp-server/                # fastMCP å·¥å…·æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ server.py
â”‚   â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”‚   â”œâ”€â”€ order.py
â”‚   â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚
â”‚   â””â”€â”€ vllm/                      # vLLM æœåŠ¡ï¼ˆå¯é€‰å®¹å™¨åŒ–ï¼‰
â”‚       â””â”€â”€ start.sh
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start-dev.sh               # æœ¬åœ°ä¸€é”®å¯åŠ¨
â”‚   â””â”€â”€ test-chat.py               # API è°ƒè¯•è„šæœ¬
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ architecture.md            # æ¶æ„è¯´æ˜
    â”œâ”€â”€ prompts.md                 # Prompt è®¾è®¡è®°å½•
    â””â”€â”€ decisions.md               # æ¶æ„å†³ç­–è®°å½•
```

## äºŒã€æ¯ä¸ªç›®å½•æ˜¯å¹²ä»€ä¹ˆçš„ï¼ˆéå¸¸é‡è¦ï¼‰

### 1. agent-gateway/ï¼ˆæ•´ä¸ªç³»ç»Ÿçš„â€œå¤§è„‘â€ï¼‰

è¿™æ˜¯ä½ æœªæ¥ 80% æ—¶é—´ä¼šæ”¹çš„åœ°æ–¹ã€‚

1. main.py

   - FastAPI å¯åŠ¨å…¥å£
   - æä¾› /chat API
   - è°ƒç”¨ agent.runner

2. agent/runner.py

   - æ‹¼ Prompt
   - è°ƒ vLLM
   - åˆ¤æ–­æ˜¯å¦ tool_call
   - è°ƒ fastMCP
   - Loop ç›´åˆ° final answer

3. agent/prompts.py

   ```python
      SYSTEM_PROMPT = """
     ä½ æ˜¯ä¸€ä¸ªå¯ä»¥ä½¿ç”¨å·¥å…·çš„åŠ©æ‰‹ã€‚
     å½“ä¿¡æ¯ä¸è¶³æ—¶ï¼Œå¿…é¡»è°ƒç”¨å·¥å…·ã€‚
     """
   ```

4. agent/tools.py

   - æŠŠ fastMCP çš„å·¥å…·
   - è½¬æˆ OpenAI / vLLM çš„ tool schema

5. llm/vllm_client.py

   - vLLM OpenAI-compatible client
   - å¯æ— ç¼æ¢ OpenAI / SiliconFlow / Together

6. mcp/client.py

   - fastMCP Client å°è£…
   - ç®¡è¿æ¥ & é”™è¯¯

7. rag/ragflow.py

   - è°ƒ RAGFlow API
   - è·å– retrieved_context
     ğŸ‘‰ RAGFlow è¢«å½“æˆâ€œå¤–éƒ¨çŸ¥è¯†æœåŠ¡â€

### 2. mcp-server/ï¼ˆä½ çš„â€œæ‰‹å’Œè„šâ€ï¼‰

- æ‰€æœ‰ä¸šåŠ¡èƒ½åŠ›éƒ½åœ¨è¿™é‡Œ
- ä¸€ä¸ª tool = ä¸€ä¸ªå‡½æ•°
- å®Œå…¨ç‹¬ç«‹éƒ¨ç½²

### 3. vllm/

- ä¸ä¸€å®šæ”¾åœ¨ repo
- è¿™é‡Œä¸»è¦æ˜¯ï¼š
  1. å¯åŠ¨è„šæœ¬
  2. æ¨¡å‹é…ç½®

### 4. docs/ï¼ˆå¼ºçƒˆå»ºè®®ä¿ç•™ï¼‰

## ä¸‰ã€æœ€å°å¯è¿è¡Œå…³é”®æ–‡ä»¶ç¤ºä¾‹

- agent-gateway/app/main.py

  ```python
    from fastapi import FastAPI
    from schemas.chat import ChatRequest
    from agent.runner import run_agent

    app = FastAPI()

    @app.post("/chat")
    async def chat(req: ChatRequest):
        return {
            "answer": await run_agent(req.query)
        }
  ```

- schemas/chat.py

  ```python
    from pydantic import BaseModel

    class ChatRequest(BaseModel):
        query: str

  ```

- rag/ragflow.py

  ```python
  import requests

  def fetch_context(query: str) -> str:
      resp = requests.post(
          "http://ragflow:9380/api/v1/chat",
          json={"query": query}
      )
      return resp.json()["context"]

  ```

## å››ã€docker-composeï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰

```yaml
version: "3.9"
services:
  agent:
    build: ./services/agent-gateway
    ports:
      - "9000:9000"
    env_file: .env

  mcp:
    build: ./services/mcp-server
    ports:
      - "8002:8002"

  vllm:
    image: vllm/vllm-openai
```

## äº”ã€ä¸ºä»€ä¹ˆè¿™ä¸ªç»“æ„æ˜¯â€œå¯¹çš„â€

- âœ” è§£è€¦
- âœ” å¯æ›¿æ¢
- âœ” æ˜“æ‰©å±•
- âœ” ç¬¦åˆ Agent å‘å±•æ–¹å‘

- ä½ ä»¥åå¯ä»¥è½»æ¾åŠ ï¼š

  - å¤š Agent
  - Planner / Executor
  - Tool æƒé™æ§åˆ¶
  - Memory

## å…­ã€ä½ æ¥ä¸‹æ¥æœ€åˆç†çš„ä¸‰æ­¥

1. Step 1
   ğŸ‘‰ å•ç‹¬è·‘ï¼š

   - vLLM
   - fastMCP
   - agent-gatewayï¼ˆä¸æ¥ RAGï¼‰

1. Step 2
   ğŸ‘‰ æ¥ RAGFlowï¼Œåªåš context

1. Step 3
   ğŸ‘‰ åŠ å¤æ‚å·¥å…· / å¤šè½®
