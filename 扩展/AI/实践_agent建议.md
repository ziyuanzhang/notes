# agent

## Agent 设计模式（Agent 框架与策略）

1. ChainofThought（CoT+思维链）：

   核心思想：让模型在回答前，把推理过程一步步写出来。不是一口气报出答案，而是把整个推理过程展示出来。

2. Self-Ask（自问自答）：

   核心思想：让模型在回答时学会“反问自己”，把大问题拆成多个小问题，然后逐个回答。

3. ReAct（推理 + 行动）：

   核心思想：在推理（Reasoning）和外部行动（Acting，比如调用搜索引擎或 API）之间交替进行。

4. Plan-and-Execute（计划与执行）：

   核心思想：把任务拆成两个阶段，先生成计划（Planning），再逐步执行（Execution）。

5. TreeofThoughts（ToT，树状思维）：

   核心思想：不是单线思维，而是生成多条思路分支，像树一样展开，再通过评估机制选出最佳分支。

6. Reflexion/IterativeRefinement（反思与迭代优化）

   核心思想：Agent 具备自我纠错的能力，犯错后会总结失败原因，再带着反思尝试下一次。

7. Role-playingAgents（角色扮演式智能体或者机器是多智能体协作）

   核心思想：把任务拆分给不同角色的 Agent，每个 Agent 都有专属职责，通过对话协作完成任务。

## 🔑 七大上下文工程原则

### 围绕 KV 缓存进行设计

关键指标：KV-cache 命中率 → 直接影响延迟与成本（如 Claude Sonnet 缓存 vs 非缓存成本差 10 倍）。
实践建议：
保持系统提示前缀完全稳定（避免时间戳等动态内容）；
上下文只追加、不修改（确保序列化确定性）；
必要时手动插入缓存断点；
自托管时启用前缀缓存（如 vLLM + 会话 ID 路由）。

### 遮蔽（Masking），而非移除工具

问题：动态增减工具会破坏 KV 缓存，并导致模型困惑（引用已删除工具）。
解决方案：
使用状态机 + logits 掩码控制可用动作；
利用响应预填充（response prefilling）约束函数调用：
自动 / 必需 / 指定 三种模式；
工具命名带统一前缀（如 browser*, shell*），便于按组掩码。

### 使用文件系统作为上下文

挑战：长上下文成本高、性能下降、易超限。
创新思路：将文件系统视为外部记忆：
模型可读写文件（如保存网页快照、中间结果）；
上下文仅保留可恢复的引用（如 URL、文件路径）；
实现无损压缩，避免信息永久丢失；
展望：SSM（状态空间模型）+ 外部记忆 = 高效新型智能体。

### 通过复述操控注意力

机制：创建并持续更新 todo.md 文件。
作用：
将全局目标复述到上下文末尾；
抵抗“注意力稀释”和“目标遗忘”；
利用 LLM 的近期偏好，自然引导注意力聚焦当前任务。

### 保留错误的内容

哲学：失败是智能体循环的正常部分。
反直觉做法：不隐藏错误，而是将其保留在上下文中。
效果：
模型通过观察失败→结果→堆栈，隐式学习纠错；
提升错误恢复能力——这是真实智能体的关键标志。

### 不要被少样本示例所困

陷阱：重复的行动-观察对会诱导模型机械模仿，导致僵化或幻觉。
对策：
在上下文中引入受控多样性（措辞、格式、顺序微调）；
打破模式依赖，提升泛化与适应性。

### 结论：上下文即架构

上下文工程虽“不优雅”（戏称“随机研究生下降”），但极其有效；
智能体的行为、效率、鲁棒性，由上下文结构决定；
未来智能体的发展，将依赖于对上下文的精细设计。
💡 核心洞见提炼
表格
维度 传统思维 Manus 实践
模型角色 需微调适配任务 利用上下文泛化，模型即平台
上下文 被动输入 主动设计的运行时架构
错误处理 隐藏重试 保留并利用作为学习信号
记忆管理 全放上下文 外部化到文件系统
工具管理 动态加载 静态定义 + 动态掩码
✅ 对开发者的启示
如果你正在构建 AI Agent：
优先优化 KV 缓存命中率（成本与延迟的关键）；
避免频繁修改上下文前缀；
用掩码代替工具切换；
把文件系统当作第二大脑；
让智能体“写日记”（如 todo.md）来聚焦目标；
拥抱错误，让它成为上下文的一部分；
警惕少样本提示的“催眠效应”。
“智能体的未来将一次构建一个上下文。好好设计它们吧。”
