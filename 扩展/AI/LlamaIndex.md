# LlamaIndex

## RAG 的 5 个阶段

1. 加载：这指的是将数据从其存储位置（无论是文本文件、PDF、其他网站、数据库还是 API）导入到您的工作流程中。
2. 索引：这意味着创建一种数据结构，以便查询数据。对于 LLM（语言学习模型）而言，这几乎总是意味着创建 vector embeddings 数据含义的数值表示，以及其他多种元数据策略，以便轻松准确地找到与上下文相关的数据。
3. 存储：一旦数据被索引，您几乎总是希望存储索引以及其他元数据，以避免重新索引。
4. 查询：对于任何给定的索引策略，您可以使用 LLM 和 LlamaIndex 数据结构进行查询，包括子查询、多步骤查询和混合策略。
5. 评估：任何流程的关键步骤之一就是检查其相对于其他策略的有效性，或者在进行更改时进行评估。评估提供客观的衡量标准，用于衡量您对查询的响应的准确性、可靠性和速度。

loading --》indexing --》storing --》querying --》evaluating

### RAG 的重要概念

- 加载阶段：

  1. 节点/文档(Documents / Nodes)

     - Document 是 LlamaIndex 中容器的概念，它可以包含任何数据源，包括，PDF 文档（`非结构化数据`），API 响应（`程序数据`），或来自数据库的数据（`结构化数据`）。
     - Node 是 LlamaIndex 中数据的最小单元，代表了一个 Document 的分块。它还包含了元数据，以及与其他 Node 的关系信息。这使得更精确的检索操作成为可能。

  2. 数据连接器(Data connectors): 通常称为 Reader

     - 从不同的数据源和数据格式中提取数据，并将其转换为 Documents 和 Nodes。

- 索引阶段：

  1. 索引(Data Indexes): 数据向量化

     - LlamaIndex 提供便利的工具，帮助开发者为注入的数据建立索引，使得未来的检索简单而高效。
     - 通常涉及“生成索引”（vector embeddings 又称向量嵌入、向量化），这些索引存储在一个名为“索引库”的专用数据库中（vector store 又称向量存储）。
     - 索引还可以存储各种关于数据的元数据。

  2. 嵌入(embeddings): LLM 生成“数据的数值表示”

     - 在筛选数据相关性时，LlamaIndex 会将查询转换为嵌入，而您的向量存储将找到与查询的嵌入在数值上相似的数据。

- 查询阶段：

  1. 检索器(Retrievers): 它定义如何高效地从知识库，基于查询，检索相关上下文信息;

     - 检索策略是决定检索数据的相关性和效率的关键。

  2. 路由器(Routers): 路由器决定"使用哪个检索器"从知识库中检索相关上下文;

     - 路由器(RouterRetriever 类)负责选择一个或多个候选检索器来执行查询。它们使用选择器(根据每个候选者的元数据和查询)来选择最佳选项。

  3. 节点处理器(Node Postprocessors): 接收一组检索到的节点，并对其应用转换、过滤、重新排序逻辑；
  4. 响应合成器(Response Synthesizers): 它基于用户的查询，和一组检索到的文本块(形成上下文)，利用 LLM 生成响应;

* RAG 管道包括:
  - Query Engines（查询引擎）：端到端的管道，允许用户基于知识库，以自然语言提问，并获得回答，以及相关的上下文。
  - Chat Engines（聊天引擎）：端到端的管道，允许用户基于知识库进行对话(多次交互，会话历史)。
  - Agents（代理）：它是一种由 LLM 驱动的自动化决策器。代理可以像查询引擎或聊天引擎一样使用。主要区别在于，代理动态地决定最佳的动作序列，而不是遵循预定的逻辑。这为其提供了处理更复杂任务的额外灵活性。
